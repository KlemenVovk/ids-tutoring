"use strict";(self.webpackChunktutoring=self.webpackChunktutoring||[]).push([[607],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),h=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=h(e.components);return a.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=h(n),c=o,m=p["".concat(l,".").concat(c)]||p[c]||u[c]||r;return n?a.createElement(m,i(i({ref:t},d),{},{components:n})):a.createElement(m,i({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:o,i[1]=s;for(var h=2;h<r;h++)i[h]=n[h];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},6600:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>h});var a=n(7462),o=(n(7294),n(3905));const r={title:"Session 1 - Git and Python for data science",sidebar_position:3},i="Git and Python for data science",s={unversionedId:"session1",id:"session1",title:"Session 1 - Git and Python for data science",description:"Live demo: repository",source:"@site/docs/session1.md",sourceDirName:".",slug:"/session1",permalink:"/ids-tutoring/session1",draft:!1,editUrl:"https://github.com/KlemenVovk/ids-tutoring/edit/master/docs/session1.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"Session 1 - Git and Python for data science",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Session 0 - prerequisites",permalink:"/ids-tutoring/session0"},next:{title:"Session 2 - web scraping",permalink:"/ids-tutoring/session2"}},l={},h=[{value:"Reproducibility",id:"reproducibility",level:2},{value:"The things that we will do to ensure reproducibility in the IDS course",id:"the-things-that-we-will-do-to-ensure-reproducibility-in-the-ids-course",level:3},{value:"Git",id:"git",level:2},{value:"Core terminology",id:"core-terminology",level:3},{value:"Git vs Github",id:"git-vs-github",level:3},{value:"What should and shouldn&#39;t be tracked in git",id:"what-should-and-shouldnt-be-tracked-in-git",level:3},{value:"Workflows",id:"workflows",level:3},{value:"Single person project",id:"single-person-project",level:4},{value:"Team project",id:"team-project",level:4},{value:"Conda",id:"conda",level:2},{value:"Creating a new environment",id:"creating-a-new-environment",level:3},{value:"Exporting an environment for reproducibility",id:"exporting-an-environment-for-reproducibility",level:3},{value:"Restoring an environment",id:"restoring-an-environment",level:3},{value:"Python for data science",id:"python-for-data-science",level:2},{value:"If you are just starting out...",id:"if-you-are-just-starting-out",level:3},{value:"The Python ecosystem",id:"the-python-ecosystem",level:3},{value:"Useful builtin modules",id:"useful-builtin-modules",level:3},{value:"Useful external libraries",id:"useful-external-libraries",level:3},{value:"FAQ",id:"faq",level:2},{value:"What git platform should I use?",id:"what-git-platform-should-i-use",level:3},{value:"How do I seed randomness and what does it mean?",id:"how-do-i-seed-randomness-and-what-does-it-mean",level:3},{value:"When to create a python (conda) environment?",id:"when-to-create-a-python-conda-environment",level:3},{value:"Can I use pip inside a conda environment?",id:"can-i-use-pip-inside-a-conda-environment",level:3},{value:"I installed a package and the conda environment broke (some packages I previously installed don&#39;t work anymore)",id:"i-installed-a-package-and-the-conda-environment-broke-some-packages-i-previously-installed-dont-work-anymore",level:3},{value:"I&#39;m importing a function into a notebook from a python file. However, when I change the function in the python file, and import it again in the notebook, nothing changes.",id:"im-importing-a-function-into-a-notebook-from-a-python-file-however-when-i-change-the-function-in-the-python-file-and-import-it-again-in-the-notebook-nothing-changes",level:3},{value:"I selected the correct kernel in the Python notebook, but I can&#39;t run anything.",id:"i-selected-the-correct-kernel-in-the-python-notebook-but-i-cant-run-anything",level:3},{value:"I can&#39;t select the environment I created in VSCode (not shown in VSCode when selecting a kernel)",id:"i-cant-select-the-environment-i-created-in-vscode-not-shown-in-vscode-when-selecting-a-kernel",level:3},{value:"If we&#39;re able to get the HTML of a page with beautifulsoup, are there any scenarios where it wouldn&#39;t be enough and we would need to use selenium?",id:"if-were-able-to-get-the-html-of-a-page-with-beautifulsoup-are-there-any-scenarios-where-it-wouldnt-be-enough-and-we-would-need-to-use-selenium",level:3}],d={toc:h},p="wrapper";function u(e){let{components:t,...r}=e;return(0,o.kt)(p,(0,a.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"git-and-python-for-data-science"},"Git and Python for data science"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Live demo:")," ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s1"},"repository")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Solve it yourself homework problem:")," TBA after the tutoring session."),(0,o.kt)("h2",{id:"reproducibility"},"Reproducibility"),(0,o.kt)("p",null,"What do we want to achieve? In layman's terms, if someone clones your repository, runs your code according to the instructions in the README, they should get the same result as you. To do this we can use several tools (non-exhaustive list):"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Git - it takes care of versioning your code."),(0,o.kt)("li",{parentName:"ul"},"Conda/pip/poetry - (these are Python specific), you will likely use some external libraries for your work (e.g. pandas, scikit, torch, etc.), so to run your code these must be installed. These tools define what libraries are used in a single text file and then try to recreate that environment on any PC with a single command."),(0,o.kt)("li",{parentName:"ul"},"Docker - if your model or API needs to be deployed in production, you put it in a Docker container, more on this in a later tutoring session.")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"These tools enable reproducibility but don't guarantee it. Therefore, the only real test if your environment is reproducible is to try and clone the repository and create the environment yourself. Even if this works, there is no guarantee that it will work on another system. Reproducibility in general is not a solved problem.*")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"There is more to reproducibility than just code and environments: where and how do we distribute the data needed for training/evaluation? What do we use to share the hyperparameters of the models used in the study? How do we ensure that the random 70:30 train-test split is the same every time?*")),(0,o.kt)("p",null,"The instructions for reproducing should always be written in the repository README along with any instructions on where and how to get the data. We will focus on git for versioning our code and conda for defining our environments as this is what you need for the IDS course."),(0,o.kt)("h3",{id:"the-things-that-we-will-do-to-ensure-reproducibility-in-the-ids-course"},"The things that we will do to ensure reproducibility in the IDS course"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"All code will be in git (and on Github)."),(0,o.kt)("li",{parentName:"ul"},"The csv files containing the data will be stored directly in git - this is rarely the case in practice as there can be too much data, or the data is binary (audio, video, text, images) and doesn't belong in git at all."),(0,o.kt)("li",{parentName:"ul"},"The environments will be created with conda and the ",(0,o.kt)("inlineCode",{parentName:"li"},"environment.yml")," file that defines the environment will be in the git repository."),(0,o.kt)("li",{parentName:"ul"},"The README will contain ALL instructions needed to run the code."),(0,o.kt)("li",{parentName:"ul"},"We will seed all randomness in our code."),(0,o.kt)("li",{parentName:"ul"},"Later when we learn about Docker, all Dockerfiles and docker compose files will be in the repository.")),(0,o.kt)("h2",{id:"git"},"Git"),(0,o.kt)("p",null,"This is the tool you use to save your work (code), sync it to other computers, collaborate with others and help with reproducibility. Code is just a text file with a fancy file extension. Before you might have kept different versions of your code in separate folders and it was hard to remember what you added in each new revision, then if you wanted to share the code you had to send the newest folder etc. This changes today as you start using Git - a version control system that was designed to solve these issues."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Basic git",src:n(2616).Z,width:"1200",height:"787"}),"\n",(0,o.kt)("a",{parentName:"p",href:"https://jlord.us/git-it/challenges/remote_control.html"},"image source")),(0,o.kt)("h3",{id:"core-terminology"},"Core terminology"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"repository - like a folder with your code. It stores everything along with the changes of every file. This is why you can look at the history of every file and who changed what and when."),(0,o.kt)("li",{parentName:"ul"},"remote - the remote server where your code is pushed (stored)"),(0,o.kt)("li",{parentName:"ul"},"commit - a snapshot of the current state of your project. This allows you to save your current work."),(0,o.kt)("li",{parentName:"ul"},"branch - when you want to add a new feature or fix something, you typically create a copy of the current state of the repository (copy of the main/master branch) and fix it there, once you are sure the new functionality or the fix works, you merge that into the master branch. This means that if halfway through adding a feature, the client decides to ditch it, you can just delete the branch for the feature and be back on track. ",(0,o.kt)("strong",{parentName:"li"},"The goal is for the master branch to always have a working copy of your project. Other branches can contain work that can't be deployed yet.")),(0,o.kt)("li",{parentName:"ul"},"checkout - git terminology for switching between branches"),(0,o.kt)("li",{parentName:"ul"},".gitignore - a special text file that defines which files git won't track. For example if your data is 3GB of videos, you don't want to track those files and later push them to Github. The same goes for files containing sensitive information like API keys and passwords. So if you have a folder ",(0,o.kt)("inlineCode",{parentName:"li"},"data")," that holds images you use to train models, than ",(0,o.kt)("inlineCode",{parentName:"li"},"data")," should be in .gitignore")),(0,o.kt)("h3",{id:"git-vs-github"},"Git vs Github"),(0,o.kt)("p",null,"Git is a version control system that tracks your project, commits changes, pushes/pulls repositories and commits to a platform (server) that supports git. One such platform is Github. You can use git locally without Github to track changes for yourself, but if you want to share the repository with someone, you need to push it to some platform that knows how to speak git, i.e. Github, Gitlab, Bitbucket, etc. "),(0,o.kt)("h3",{id:"what-should-and-shouldnt-be-tracked-in-git"},"What should and shouldn't be tracked in git"),(0,o.kt)("p",null,"One sentence rule of thumb: put in git anything that is plain text and is not sensitive (not a password, API key) or user-environment-specific (like paths to data on the users computer)."),(0,o.kt)("p",null,"Anything binary (things you can't open in a text editor) like images, video, audio generally should NOT be in git."),(0,o.kt)("h3",{id:"workflows"},"Workflows"),(0,o.kt)("p",null,"Over the years, ",(0,o.kt)("a",{parentName:"p",href:"https://www.abtasty.com/blog/git-branching-strategies/#trunk-based-development"},"many approaches")," on how to use git were developed (git flow, Github flow, trunk-based development, etc.)."),(0,o.kt)("p",null,"However, these are approaches that are complex and meant for more professional work with many collaborators on the same repository. Since you'll be working on your own for the majority of the projects during your studies, while other times you will have max. 3 collaborators, I decided to introduce two approaches."),(0,o.kt)("h4",{id:"single-person-project"},"Single person project"),(0,o.kt)("p",null,"This will be most of your work. Since you have no collaborators, and the projects are small, you can just use the master branch for everything. As you are alone, it's still very easy to rollback commits if you break your code and you will be implementing features sequentially anyway. More branches will just mean extra work."),(0,o.kt)("h4",{id:"team-project"},"Team project"),(0,o.kt)("p",null,"From the beginning you want to have two branches that are NEVER deleted.:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"master - this always contains a working copy of your work - features may be missing, but those that are implemented, work."),(0,o.kt)("li",{parentName:"ul"},"develop - this is the branch your team works on. When a collaborator decides to add a feature, he/she creates his/her own branch from the develop branch and works on it. Once the feature is complete, the branch is merged into develop and deleted. When enough progress is made to the point it makes sense to release a new version, develop is merged into master. For the next feature, the collaborator again creates his branch from develop and repeats the loop.")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Proposed team workflow",src:n(3376).Z,width:"614",height:"268"})),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://lutece.paris.fr/support/wiki/git.html"},"image source")),(0,o.kt)("p",null,"To motivate: on projects where the product is a web application (like an API), the pipeline is usually set in a way that it automatically deploys whatever is on master. That's why master always needs to have a working copy. Otherwise, you might push a bug to master and take down the whole app. The deployment of the app can take a long time, this is why you need the develop branch so you release a bunch of features at once to minimize downtime. Otherwise you would trigger a new release on every small addition resulting in your app being down all the time. This is even worse if you are exposing a predictive model which is retrained on every deployment."),(0,o.kt)("p",null,"This is also how your projects for the DS project competition will need to be structured."),(0,o.kt)("h2",{id:"conda"},"Conda"),(0,o.kt)("p",null,"Let's say that for our project we want to use Python 3.10, along with the pandas external library (don't worry, you can add more libraries on the fly should you need them). We start by creating the Python environment. Think of the environment as a separate installation of Python with only the libraries you need for a specific project and nothing more."),(0,o.kt)("h3",{id:"creating-a-new-environment"},"Creating a new environment"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda create -n my_env python=3.10\n")),(0,o.kt)("p",null,"The above creates a Python 3.10 environment (you may or may not specify the exact version). Next, we have to tell our system to use that environment for Python and not the default (",(0,o.kt)("inlineCode",{parentName:"p"},"base"),") one. In other word, when we execute ",(0,o.kt)("inlineCode",{parentName:"p"},"python script.py")," we want the ",(0,o.kt)("inlineCode",{parentName:"p"},"python")," to refer to the Python in our environment, not the one that comes with our system. We do this by activating the environment:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda activate my_env\n")),(0,o.kt)("p",null,"Ok so we have a fresh installation of Python 3.10. Now let's install pandas in it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda install -c conda-forge pandas\n")),(0,o.kt)("p",null,"What's this ",(0,o.kt)("inlineCode",{parentName:"p"},"-c conda-forge")," switch you ask? Conda has its own default channel of packages available for installation. The default channel doesn't always contain what you need, so other channels are available and you can specify them with ",(0,o.kt)("inlineCode",{parentName:"p"},"-c channel_name"),". ",(0,o.kt)("inlineCode",{parentName:"p"},"conda-forge")," is very popular and has tons of packages. If the default channel doesn't have a library you are looking for, then it's a good idea to try with ",(0,o.kt)("inlineCode",{parentName:"p"},"-c conda-forge"),". Personally, I always use ",(0,o.kt)("inlineCode",{parentName:"p"},"-c conda-forge")," and haven't had any issues yet. "),(0,o.kt)("p",null,"That's it. At this point it's also a good idea to save the environment to a file so that we can reproduce it later (don't forget to do this when you add new packages too)."),(0,o.kt)("h3",{id:"exporting-an-environment-for-reproducibility"},"Exporting an environment for reproducibility"),(0,o.kt)("p",null,"We can export the environment to environment.yml with the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda env export > environment.yml\n")),(0,o.kt)("p",null,"If we take a look at the exported file we see something like:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"name: my_env\nchannels:\n- conda-forge\ndependencies:\n...\n- numpy=1.26.0=py310hb13e2d6_0\n- openssl=3.1.3=hd590300_0\n- pandas=2.1.1=py310hcc13569_1\n- pip=23.3=pyhd8ed1ab_0\n- python=3.10.12=hd12c33a_0_cpython\n- python-dateutil=2.8.2=pyhd8ed1ab_0\n- python-tzdata=2023.3=pyhd8ed1ab_0\n- python_abi=3.10=4_cp310\n...\n")),(0,o.kt)("p",null,"You probably noticed two things:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"There are a lot more dependencies than you expected (remember, we installed just Python and pandas)"),(0,o.kt)("li",{parentName:"ol"},"There are weird strings after the second ",(0,o.kt)("inlineCode",{parentName:"li"},"=")," in each dependency line.")),(0,o.kt)("p",null,"To address the first point, remember that pandas is just a bunch of python files packaged in a single module (library). This means that those files can also use any other libraries that you don't need yourself. In tech speak, pandas ",(0,o.kt)("em",{parentName:"p"},"depends")," on a lot of other libraries, one of them being numpy."),(0,o.kt)("p",null,"Focusing on the second point, these strings define the builds. Packages like numpy are built (compiled) for a specific system architecture (the most popular being x86) for a specific OS. To differentiate between numpy 1.26.0 for Linux for x86 and numpy 1.26.0 for MacOS for M1 macbooks we use these build strings. Now, what will happen if I'm using Linux on a x86 laptop (basically all laptops, apart from the M1/M2 macbooks), export the environment and give you the ",(0,o.kt)("inlineCode",{parentName:"p"},"environment.yml")," file to reproduce on your shiny new M2 macbook? Suddenly (some) builds might lead to packages that are not available/don't work on the M2 which means that you won't be able to recreate my environment. This is why reproducibility is hard and isn't a solved problem."),(0,o.kt)("p",null,"Why not just remove the builds then and say 'ok conda, just install any numpy 1.26.0 you can'? This is better and can be done in conda with:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda env export --no-builds > environment.yml \n")),(0,o.kt)("p",null,"The result will look something like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"name: my_env\nchannels:\n- conda-forge\ndependencies:\n...\n- numpy=1.26.0\n- openssl=3.1.3\n- pandas=2.1.1\n- pip=23.3\n- python=3.10.12\n- python-dateutil=2.8.2\n- python-tzdata=2023.3\n- python_abi=3.10\n...\n")),(0,o.kt)("p",null,"However, what if some dependency is only needed on Windows and not on Linux? Then conda will try to install a package that doesn't exist for Linux and the environment again won't be reproducible."),(0,o.kt)("p",null,"What we can do though, is only list the packages we explicitly installed through ",(0,o.kt)("inlineCode",{parentName:"p"},"conda install")," and expect that the target system will have some version of those. This can be done with:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda env export --from-history > environment.yml\n")),(0,o.kt)("p",null,"The resulting environment.yml is:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"name: my_env\nchannels:\n- conda-forge\ndependencies:\n- pandas\n- python=3.10\n")),(0,o.kt)("p",null,"This is currently the ",(0,o.kt)("a",{parentName:"p",href:"https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#exporting-an-environment-file-across-platforms"},"conda recommended way to do cross-platform environment sharing")," and it ",(0,o.kt)("strong",{parentName:"p"},"should")," work. Again, it isn't guaranteed. An example of when this crashes and burns is if a package we explicitly installed simply isn't available through conda on the target system. From personal experience (DS Project Competition): OpenCV needs to be compiled from source to run on the Jetson nano with CUDA support. This is impossible to solve using only conda and is where docker comes in."),(0,o.kt)("h3",{id:"restoring-an-environment"},"Restoring an environment"),(0,o.kt)("p",null,"To restore an environment, we just tell conda to create a new environment from a given ",(0,o.kt)("inlineCode",{parentName:"p"},"environment.yml"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda env create -f environment.yml\n")),(0,o.kt)("p",null,"and then we can activate it (the name is also defined in environment.yml)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda activate my_env\n")),(0,o.kt)("h2",{id:"python-for-data-science"},"Python for data science"),(0,o.kt)("h3",{id:"if-you-are-just-starting-out"},"If you are just starting out..."),(0,o.kt)("p",null,"There are many programming practice websites available (",(0,o.kt)("a",{parentName:"p",href:"https://leetcode.com/"},"LeetCode"),", ",(0,o.kt)("a",{parentName:"p",href:"https://coderbyte.com/"},"CoderByte"),", ",(0,o.kt)("a",{parentName:"p",href:"https://projecteuler.net/"},"Project Euler")," - don't do this, it tests more math than programming, ",(0,o.kt)("a",{parentName:"p",href:"https://adventofcode.com/"},"Advent of code"),", etc.). I would not recommend any of these. These are sites that are meant for software engineers to prepare for technical interviews and therefore test algorithmic and data structure knowledge. I don't think you need to practice/know how to invert a binary tree, or how to implement Dijkstra's algorithm to search for the shortest path etc. This is why I would recommend you to go to ",(0,o.kt)("a",{parentName:"p",href:"https://kaggle.com/"},"Kaggle"),", pick a dataset/challenge and work on it, see what others have done, etc. This is much closer to the work you will be doing throughout your master's studies."),(0,o.kt)("h3",{id:"the-python-ecosystem"},"The Python ecosystem"),(0,o.kt)("p",null,"Python benefits from a huge ecosystem of libraries to do basically anything. Here are some that you might find useful (those that I think are directly applicable for your projects are marked with ",(0,o.kt)("strong",{parentName:"p"},"[recommended for IDS]"),"), you can use anything else though as long as you achieve the goal."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Some of these are opinionated choices and/or things that I've encountered on my limited sample size of industry projects, I am nowhere near an expert. I've tried to stick to popular libraries (based on stackoverflow surveys, pip installs and github trends). As always you should do your own research.*")),(0,o.kt)("p",null,"We won't go over all of these during the tutoring session, I've just listed them here so that you know they exist or what to search for if/when you are doing your own research."),(0,o.kt)("h3",{id:"useful-builtin-modules"},"Useful builtin modules"),(0,o.kt)("p",null,"These are libraries that come bundled with Python and you can just import without installing anything else:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/argparse.html"},"argparse")," - when you need to create a command line interface (CLI), so you can give variable values directly from the terminal when executing the script, e.g. ",(0,o.kt)("inlineCode",{parentName:"li"},"python script.py --input-file my_data.csv --verbose"),". For a popular external alternative see ",(0,o.kt)("a",{parentName:"li",href:"https://typer.tiangolo.com/"},"typer"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/datetime.html"},"datetime")," - working with dates and times"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/os.html"},"os")," - working with directories (list and walk) and files (copy, remove)"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/sys.html"},"sys")," - getting info about the host system"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/re.html"},"re")," - using regular expressions (regex)"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/random.html"},"random")," - generating random numbers"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/unittest.html"},"unittest")," - for writing code tests. One popular external alternative: ",(0,o.kt)("a",{parentName:"li",href:"https://docs.pytest.org/en/7.4.x/"},"pytest")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/profile.html"},"profile")," - which functions in my script take the longest time to execute? useful for knowing what to optimize"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/timeit.html"},"timeit")," - run the same function multiple times and measure how long it takes to execute on average"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/sqlite3.html"},"sqlite3")," - when you need an SQL database that can be saved and read from a single file"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/json.html"},"json")," - parse/save json"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/tarfile.html"},"tarfile")," - read/write .tar archives"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/gzip.html"},"gzip")," - read/write .gz archives"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/zipfile.html"},"zipfile")," - read/write zip archives")),(0,o.kt)("p",null,"You can find all available builtin modules ",(0,o.kt)("a",{parentName:"p",href:"https://docs.python.org/3.12/library/index.html"},"here")," (be careful to select the Python version you are using on the left as the modules change)."),(0,o.kt)("h3",{id:"useful-external-libraries"},"Useful external libraries"),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://pandas.pydata.org/"},"pandas")," - reading, saving, and manipulating tabular data ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"If you are working with tabular data, it should be in a pandas dataframe (a table). It knows how to read and save in a lot of popular formats (from csv and excel to binary formats like feather) while also exposing a simple interface for selecting data and computing some basic statistics. It also integrates well with other libraries (i.e. seaborn)."),(0,o.kt)("p",null,"A use case example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\n\n# Load the data from a CSV file\nsales_data = pd.read_csv('sales_data.csv')\n# Display the first few rows of the data\nprint(sales_data.head())\n# Get basic statistics about the data (min, mean, max, number of missing values etc.)\nsummary_stats = sales_data.describe()\n# Calculate the total sales for the team\ntotal_sales = sales_data['SalesAmount'].sum()\n# Find the top salesperson\ntop_salesperson = sales_data.loc[sales_data['SalesAmount'].idxmax()]\n# Filter data for high-performing salespeople\nhigh_performers = sales_data[sales_data['SalesAmount'] > 10000]\n# Group the data by sales region and calculate the average sales for each region\navg_sales_by_region = sales_data.groupby('Region')['SalesAmount'].mean()\n# Save the computed metrics to CSV files\nsummary_stats.to_csv('summary_stats.csv')\ntop_salesperson.to_frame().T.to_csv('top_salesperson.csv')\nhigh_performers.to_csv('high_performers.csv')\navg_sales_by_region.to_frame().to_csv('avg_sales_by_region.csv')\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html"},"matplotlib")," - drawing pretty charts ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"This is the go-to library for drawing graphs in Python. You can draw anything from bar charts to box and scatter plots."),(0,o.kt)("p",null,"A use case example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create a Pandas DataFrame with sales data\ndata = {\n    'Region': ['East', 'East', 'North', 'North', 'West', 'West', 'South', 'South'],\n    'Year': [2020, 2021, 2020, 2021, 2020, 2021, 2020, 2021],\n    'Sales': [50000, 55000, 52000, 60000, 48000, 52000, 45000, 49000]\n}\n\ndf = pd.DataFrame(data)\n\n# Define unique regions and years\nregions = df['Region'].unique()\nyears = df['Year'].unique()\n\n# Set the width of each bar\nbar_width = 0.35\nindex = range(len(regions))\n\n# Create grouped bars by iterating over years\nplt.figure()\n\nfor i, year in enumerate(years):\n    sales_by_year = df[df['Year'] == year]\n    sales = [sales_by_year[sales_by_year['Region'] == region]['Sales'].values[0] for region in regions]\n    plt.bar([pos + bar_width * i for pos in index], sales, bar_width, label=str(year))  # Convert year to string\n\nplt.xlabel('Region')\nplt.ylabel('Sales')\nplt.title('Sales by Region and Year (Matplotlib)')\nplt.xticks([pos + bar_width for pos in index], regions)\nplt.legend(title='Year')\nplt.savefig('grouped_sales_matplotlib.pdf')\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"matplotlib barchart",src:n(2770).Z,width:"640",height:"480"}))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://seaborn.pydata.org/"},"seaborn")," - drawing pretty charts easily ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"matplotlib can be a bit clunky to use. It also doesn't know how to directly work with pandas dataframes. This is why over the years, many libraries were built on top of matplotlib to offer an easier way of doing basic charts. One of these is seaborn which knows how to work with dataframes directly (you just specify the column name), as well as some sensible defaults and functionality (knows how to group by category without you having to do it manually with for loops, knows how to compute confidence intervals, includes a legend automatically when needed, etc.)."),(0,o.kt)("p",null,"Let's draw the same barchart as in the matplotlib section."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Use the default theme (many available)\nsns.set_theme()\n\n# Create a Pandas DataFrame with sales data\ndata = {\n    'Region': ['East', 'East', 'North', 'North', 'West', 'West', 'South', 'South'],\n    'Year': [2020, 2021, 2020, 2021, 2020, 2021, 2020, 2021],\n    'Sales': [50000, 55000, 52000, 60000, 48000, 52000, 45000, 49000]\n}\ndf = pd.DataFrame(data)\n\n# Use Seaborn to create a grouped bar chart (sales per year grouped by region)\nplt.figure()\nsns.barplot(x='Region', y='Sales', hue='Year', data=df)\nplt.xlabel('Region')\nplt.ylabel('Sales [EUR]')\nplt.title('Sales by region and year')\nplt.savefig(\"grouped_sales_seaborn.pdf\")\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"bar chart",src:n(9359).Z,width:"640",height:"480"})),(0,o.kt)("p",null,"See how much less code it took?")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://numpy.org/"},"numpy")," - vector and matrix math ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"If you need to do math (matrix/vector computations) that runs quickly, you use this. Other libraries (pandas, scikit-learn, torch, etc.) all use it under the hood."),(0,o.kt)("p",null,"Showcase:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\n\n# Creating and manipulating 1D data (vectors)\nvector = np.array([1, 2, 3, 4, 5])\n\n# Element-wise operations on the vector\nvector_squared = np.square(vector)  # Square each element\nvector_sqrt = np.sqrt(vector)  # Calculate the square root of each element\nvector_sum = np.sum(vector)  # Sum of all elements\n\n# Matrix operations\nmatrix_A = np.array([[1, 2], [3, 4]])\nmatrix_B = np.array([[2, 0], [1, 3]])\n\n# Matrix multiplication\nmatrix_result = np.dot(matrix_A, matrix_B)\n\n# Statistics\ndata = np.array([10, 20, 30, 40, 50])\nmean = np.mean(data)\nstd_dev = np.std(data)\nmin_value = np.min(data)\nmax_value = np.max(data)\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://scipy.org/"},"scipy")," - mainly math and stats functions that you would have to implement manually in numpy"),(0,o.kt)("p",null,"scipy provides many specialized functions for hypothesis testing, probability distributions, t-tests, integration, interpolation, correlation coefficients, distance matrices etc. that you would have to implement manually in numpy."),(0,o.kt)("p",null,"An example of computing Pearson correlation coefficient:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import numpy as np\nfrom scipy import stats\n\n# Create sample data\nvariable1 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nvariable2 = np.array([2, 4, 5, 7, 8, 10, 11, 13, 14, 16])\n\n# Calculate the Pearson correlation coefficient\ncorrelation_coefficient, p_value = stats.pearsonr(variable1, variable2)\n\nprint(f"Pearson Correlation Coefficient: {correlation_coefficient:.2f}")\nprint(f"P-Value: {p_value:.2f}")\n\nif p_value < 0.05:\n    print("There is a statistically significant correlation.")\nelse:\n    print("There is no statistically significant correlation.")\n\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://scikit-learn.org/stable/"},"scikit-learn")," - shallow predictive models ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"This is what you use for fitting most shallow predictive models (regression, SVM, random forests, etc.). It provides a very consistent interface to all models along with many supporting functions for hyperparameter optimization, metric computations, clustering, model selection, dimensionality reduction, data preprocessing etc."),(0,o.kt)("p",null,"An example of fitting a random forest to the breast cancer dataset:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Import scikit-learn and load a more complex dataset\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the Breast Cancer dataset\ndata = load_breast_cancer()\nX = data.data  # Features\ny = data.target  # Target labels\n\n# Split the dataset into a training set and a test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize a Random Forest classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Fit the classifier to the training data\nrf_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = rf_classifier.predict(X_test)\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f"Accuracy: {accuracy*100:.2f}%")\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://xgboost.readthedocs.io/en/stable/#"},"xgboost")," - gradient boosting models"),(0,o.kt)("p",null,"A library that implements gradient boosting models. ",(0,o.kt)("strong",{parentName:"p"},"In my limited experience"),", when I got a prebuilt predictive model from the industry, it was most likely xgboost or a random forest from scikit."),(0,o.kt)("p",null,"Example on the same dataset as scikit above:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import xgboost as xgb\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the Breast Cancer dataset\ndata = load_breast_cancer()\nX = data.data  # Features\ny = data.target  # Target labels (0 or 1)\n\n# Split the dataset into a training set and a test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize and configure the XGBoost classifier\nxgb_classifier = xgb.XGBClassifier(\n    learning_rate=0.1,\n    n_estimators=100,\n    max_depth=3,\n    objective="binary:logistic",\n    random_state=42\n)\n\n# Fit the classifier to the training data\nxgb_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = xgb_classifier.predict(X_test)\n\n# Calculate the accuracy of the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f"Accuracy: {accuracy*100:.2f}%")\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://tqdm.github.io/"},"tqdm")," - very simple progress bars for loops ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"A quality of life library with the purpose of providing a progress bar for any loop along with a time left estimate. To use, you just wrap your list/generator with ",(0,o.kt)("inlineCode",{parentName:"p"},"tqdm()"),"."),(0,o.kt)("p",null,"Example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from tqdm import tqdm\nimport time\n\n# Create a list of items to iterate through\nitems = range(10)\n\n# Create a tqdm object to wrap the loop\nfor item in tqdm(items):\n    # Simulate a time-consuming task\n    time.sleep(0.5)\n\n# The progress bar will update as the loop iterates, showing the progress.\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://pypi.org/project/python-dotenv/"},"python-dotenv")," - use environment variables to store sensitive/user specific information that doesn't belong in git."),(0,o.kt)("p",null,"It can happen that your program will require sensitive information (e.g. an API key to access some data) which should NOT be in version control. One of the ways you can solve this issue is with environment variables. These are variables that specific to your environment/pc. An example of an environment variable: if you type ",(0,o.kt)("inlineCode",{parentName:"p"},"echo $USER")," in your terminal, you will print the environment variable ",(0,o.kt)("inlineCode",{parentName:"p"},"USER")," which contains the username of the current user."),(0,o.kt)("p",null,"Let's say we want to access the database somewhere on the internet. To do so, we need the URL of the database and a key. Both of these should never be in git, so we create a file ",(0,o.kt)("inlineCode",{parentName:"p"},".env")," with the following contents:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'DATABASE_URL="mysql://user:password@localhost/mydatabase"\nSECRET_KEY="mysecretkey"\n')),(0,o.kt)("p",null,"This file is in the same folder as our Python script. Then we can access these variables like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from dotenv import load_dotenv\nimport os\n\n# Load environment variables from the .env file\nload_dotenv()\n\n# Access environment variables\ndatabase_url = os.getenv("DATABASE_URL")\nsecret_key = os.getenv("SECRET_KEY")\n\n# Display the environment variables\nprint(f"Database URL: {database_url}")\nprint(f"Secret Key: {secret_key}")\n\naccess_database(database_url, secret_key) # ...\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://pypi.org/project/requests/"},"requests")," - query APIs"),(0,o.kt)("p",null,"There are situations where you need to get the data on the fly and you can't have it saved locally. One such example is stock prices which change all the time. For getting and transforming such data, you can search for APIs on the internet. There are APIs for practically everything (stock prices, currency exchange rates, ChatGPT has an API you can prompt programatically, etc.). The requests library provides you with a simple interface to call such APIs."),(0,o.kt)("p",null,"To illustrate, we will use the ",(0,o.kt)("a",{parentName:"p",href:"https://api.quotable.io/random"},"Quotable API")," to get a random quote:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import requests\n\n# Define the API endpoint for a random quote\napi_url = 'https://api.quotable.io/random'\n\n# Make a GET request to the API\nresponse = requests.get(api_url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    data = response.json()\n    \n    # Extract and display the random quote\n    quote = data['content']\n    author = data['author']\n    print(f\"Random Quote: '{quote}' - {author}\")\nelse:\n    print(f\"Failed to fetch a random quote. Status code: {response.status_code}\")\n\n"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://fastapi.tiangolo.com/"},"FastAPI")," - when you need to expose data/models/functions to the internet in the form of an API."),(0,o.kt)("p",null,"What if you have a predictive model (e.g. a random forest) that you would like to expose to the internet in the form of an API? This is where FastAPI comes in. It enables you to write APIs in in Python. This is great, because if your predictive model is written in Python (which is very likely), it's much easier to integrate it into a Python API than for example a Javascript API."),(0,o.kt)("p",null,"Let's create an API that exposes your car price prediction model that you fit in scikit:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from fastapi import FastAPI\nfrom pydantic import BaseModel\nimport joblib\n\n# Create a FastAPI app\napp = FastAPI()\n\n# Load a pre-trained scikit-learn model\nmodel = joblib.load(\'your_car_price_model.pkl\')\n\n# Define a data model for input\nclass CarFeatures(BaseModel):\n    mileage: float\n    horsepower: float\n    year: int\n\n# Create a route for making price predictions\n@app.post("/predict/")\ndef predict_price(data: CarFeatures):\n    # Prepare the input data as a list\n    input_data = [[data.mileage, data.horsepower, data.year]]\n\n    # Use the pre-trained model to make price predictions\n    predicted_price = model.predict(input_data)\n\n    return {"predicted_price": predicted_price[0]}\n')),(0,o.kt)("p",null,"Now we can send mileage, horsepower and year to ",(0,o.kt)("inlineCode",{parentName:"p"},"http://localhost:8000/predict")," (remember when we talked about using the requests module to query APIs?) and we will get a response with the prediction!")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://www.selenium.dev/"},"selenium")," - automating your web browser ",(0,o.kt)("strong",null,"[recommended for IDS]")),(0,o.kt)("p",null,"Sometimes you would like to automate actions in your web browser (go to this page, type in the username and password, log in, get some data). This is when selenium comes into play. You use it to launch a web browser and programmatically send commands to it. You can use it for getting data (web scraping), testing web applications automatically, making bots (quickly buying things before they go out of stock etc.)."),(0,o.kt)("p",null,"An example of navigating to a page, logging in and getting some text:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\n# Launch a browser\ndriver = webdriver.Chrome(executable_path="/path/to/chromedriver")\n\n# Go to a webpage\ndriver.get("https://example.com/login")\n\n# Find and fill in the username and password fields\nusername_field = driver.find_element_by_id("username")  # Replace with the actual ID or name of the username input field\npassword_field = driver.find_element_by_id("password")  # Replace with the actual ID or name of the password input field\nusername_field.send_keys("your_username")\npassword_field.send_keys("your_password")\n\n# Submit the login form (e.g., clicking the login button)\nlogin_button = driver.find_element_by_id("login-button")  # Replace with the actual ID or name of the login button\nlogin_button.click()\n\n# Wait for the dashboard to load (you may need to adjust the wait time based on the webpage)\ndriver.implicitly_wait(10)\n\n# Extract data from the dashboard\ndashboard_data = driver.find_element_by_id("dashboard-data")  # Replace with the actual ID or name of the data element\ndata_text = dashboard_data.text\n\n# Print the extracted data\nprint("Dashboard Data:")\nprint(data_text)\n\n# Close the browser\ndriver.quit()\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://www.crummy.com/software/BeautifulSoup/bs4/doc/"},"beautifulsoup")," - when you need to extract data from static websites"),(0,o.kt)("p",null,"beautifulsoup is a library for parsing HTML of websites (more on this in the web scraping tutorial session). If you want to acquire data from a very static page (no login, scrolling, closing pop ups required - e.g. wikipedia), it's enough to use just beautifulsoup without selenium."),(0,o.kt)("p",null,"Example of extracting article titles from a news site:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import requests\nfrom bs4 import BeautifulSoup\n\n# Send an HTTP GET request to the web page\nurl = "https://example-news-site.com"\nresponse = requests.get(url)\n\n# Check if the request was successful (status code 200)\nif response.status_code == 200:\n    # Parse the HTML content of the page using Beautiful Soup\n    soup = BeautifulSoup(response.text, \'html.parser\')\n\n    # Find and extract the titles of articles (adjust the selectors for your specific case)\n    article_titles = soup.find_all("h2", class_="article-title")  # Replace with actual HTML selectors\n\n    # Display the extracted article titles\n    for title in article_titles:\n        print(title.text.strip())  # .strip() removes leading/trailing whitespace\n\nelse:\n    print("Failed to fetch the web page. Status Code:", response.status_code)\n'))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://www.sqlalchemy.org/"},"sqlalchemy")," - work with SQL databases from Python, the right way"),(0,o.kt)("p",null,"Working with databases from a programming language can be tricky. Wouldn't it be great if we could define a Python class that would be an equivalent of a row in a database table and we could access it by column names instead of indices? This is where ORMs (object-relational mappers) like sqlalchemy come into play. Their only purpose is to take a predefined Python object and map it to a table row and vice-versa."),(0,o.kt)("p",null,"An example that illustrates how sqlalchemy integrates into working with a database:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n# Create a SQLite database and an SQLAlchemy engine\ndb_url = "sqlite:///mydatabase.db"\nengine = create_engine(db_url)\n\n# Define a base class for declarative models\nBase = declarative_base()\n\n# Define a data model (a table)\nclass Person(Base):\n    __tablename__ = \'people\'\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, unique=True, index=True)\n\n# Create the table in the database\nBase.metadata.create_all(bind=engine)\n\n# Create a new person\nSession = sessionmaker(bind=engine)\ndb = Session()\nnew_person = Person(name="John Doe")\ndb.add(new_person)\ndb.commit()\n\n# Query and print all people in the table\npeople = db.query(Person).all()\nfor person in people:\n    print(f"ID: {person.id}, Name: {person.name}")\n')),(0,o.kt)("p",null,"Notice how we defined a class Person that has an id and a name and then we could create and read to and from the database through Python objects instead of having to write SQL statements (sqlalchemy writes these behind the scenes).")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://opencv.org/"},"opencv")," - basic operations on images"),(0,o.kt)("p",null,"This is what you use for working with images without neural networks for things like blurring, resizing, cropping, extracting edges, thresholding etc. Examples can be found ",(0,o.kt)("a",{parentName:"p",href:"https://docs.opencv.org/4.x/examples.html"},"here"),".")),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://www.nltk.org/"},"nltk")," - basic operations on human language (text)"),(0,o.kt)("p",null,"For working with human language data - when you need to tokenize a string, remove stop words before feeding the input into a deep neural network. Examples can be found ",(0,o.kt)("a",{parentName:"p",href:"https://www.nltk.org/howto.html"},"here"))),(0,o.kt)("details",null,(0,o.kt)("summary",null,(0,o.kt)("a",{href:"https://pytorch.org/"},"torch")," - deep learning"),(0,o.kt)("p",null,"This is what you use for deep learning (any kind of neural networks). There are many alternatives (tensorflow, JAX, etc.), however, this is what you will use in most courses that have projects in deep learning. Many additional libraries built on top of it exist (i.e. Lightning, ignite), do your own research. Examples are available ",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"},"here"),".")),(0,o.kt)("h2",{id:"faq"},"FAQ"),(0,o.kt)("h3",{id:"what-git-platform-should-i-use"},"What git platform should I use?"),(0,o.kt)("p",null,"There are many available platforms (Github, Gitlab, Bitbucket, etc.). For the majority of use cases, it doesn't matter. It starts to matter if you start using platform specific functions (Github actions or Gitlab CI/CD). I would recommend you to just use Github. It's widely used and has introduced tons of useful features making it possible to use Github as the single source of truth for everything about your project (code, wikis, plans, etc.). These resources for the tutorial sessions are published with a feature called Github pages. If you want to delve into such Github features, take a look at ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/features"},"this"),' to see what\'s possible and how. If you want to learn more about making git your single source of truth, read up on "gitops".'),(0,o.kt)("h3",{id:"how-do-i-seed-randomness-and-what-does-it-mean"},"How do I seed randomness and what does it mean?"),(0,o.kt)("p",null,"There are many cases where your code requires some random value - i.e. a random 70:30 train-test split needs random indices of rows, permutation testing requires random permutations etc. This causes issues with reproducibility as it's impossible to get the same results if each time you run your code you get different train-test splits (and therefore different models). This is the issue seeds solve. A seed is just a number you set as a starting point for the random number generator that Python uses under the hood. Take a look at the following snippet:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import numpy as np\n\n# Set a seed for reproducibility\nseed_value = 42\nnp.random.seed(seed_value)\n\n# Generate random numbers\nrandom_numbers = np.random.rand(5)  # Generate 5 random numbers between 0 and 1\n\nprint("Random Numbers:")\nprint(random_numbers)\n')),(0,o.kt)("p",null,"Here ",(0,o.kt)("inlineCode",{parentName:"p"},"random_numbers")," will always contain the same 5 random numbers. If you use a different seed, then it will always contain some other 5 numbers. This means that you still have random numbers, however your experiments are repeatable. Don't forget to seed all random generators (numpy uses a separate generator and seed from the python's ",(0,o.kt)("inlineCode",{parentName:"p"},"random")," builtin module, and scikit functions take a random_state parameter to define a seed)."),(0,o.kt)("h3",{id:"when-to-create-a-python-conda-environment"},"When to create a python (conda) environment?"),(0,o.kt)("p",null,"Short answer: always (1 environment per project). Each project belongs in git and should be reproducible (therefore you should have an environment per project). Furthermore, if it's a group project, then a defined environment in the git repo is a must and should be project specific as everyone will use it when working on the project. At the very least, I would recommend one environment per course - e.g. you probably won't use pandas in a computer vision course, and you won't use opencv for IDS. However you probably will use opencv for all your computer vision projects, so you can have the same environment."),(0,o.kt)("h3",{id:"can-i-use-pip-inside-a-conda-environment"},"Can I use pip inside a conda environment?"),(0,o.kt)("p",null,"Yes, however, ",(0,o.kt)("a",{parentName:"p",href:"https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#using-pip-in-an-environment"},"it is highly discouraged")," as it's an easy way to ruin your environment. If you still decide to do it, you have to follow one rule though: use pip after conda, as conda also tracks the packages you install with pip (these will be under the ",(0,o.kt)("inlineCode",{parentName:"p"},"pip")," section in your exported environment.yml)."),(0,o.kt)("h3",{id:"i-installed-a-package-and-the-conda-environment-broke-some-packages-i-previously-installed-dont-work-anymore"},"I installed a package and the conda environment broke (some packages I previously installed don't work anymore)"),(0,o.kt)("p",null,"Unfortunately, this sometimes happens. There are many possible reasons why. A simple one that comes to mind is that conda can change already installed packages. Let's say you have an environment with numpy 1.26.0 installed. Then you decide to install a library that also requires numpy, but at most of version 1.19.0. Conda will automatically uninstall your numpy 1.26.0 and install 1.19.0 and then install the package you wanted to add. Even worse, sometimes you will have unresolvable conflicts (for example consider adding another packages that wants numpy exactly 1.21.0), in that case conda can and sometimes will uninstall a package you explicitly installed, ruining your environment. The solution to this is to just create a new environment (debugging the old one is not worth it)."),(0,o.kt)("h3",{id:"im-importing-a-function-into-a-notebook-from-a-python-file-however-when-i-change-the-function-in-the-python-file-and-import-it-again-in-the-notebook-nothing-changes"},"I'm importing a function into a notebook from a python file. However, when I change the function in the python file, and import it again in the notebook, nothing changes."),(0,o.kt)("p",null,"This is a common issue, and by default, imports aren't reloaded. To solve add"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"%load_ext autoreload\n%autoreload 2\n")),(0,o.kt)("p",null,"at the very first cell in your notebook and run it. If this doesn't work make sure you saved your external python file, restart the kernel in your notebook and rerun everything."),(0,o.kt)("h3",{id:"i-selected-the-correct-kernel-in-the-python-notebook-but-i-cant-run-anything"},"I selected the correct kernel in the Python notebook, but I can't run anything."),(0,o.kt)("p",null,"You are probably missing the ",(0,o.kt)("inlineCode",{parentName:"p"},"jupyter")," package."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda install -c conda-forge jupyter\n")),(0,o.kt)("h3",{id:"i-cant-select-the-environment-i-created-in-vscode-not-shown-in-vscode-when-selecting-a-kernel"},"I can't select the environment I created in VSCode (not shown in VSCode when selecting a kernel)"),(0,o.kt)("p",null,"This can sometimes happen, the environment is fine, it's just VSCode that's not aware of it. There are two solutions (try them in order):"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Try restarting VSCode and selecting the environment again."),(0,o.kt)("li",{parentName:"ol"},"Activate the environment in the terminal ",(0,o.kt)("inlineCode",{parentName:"li"},"conda activate my_env")," and then type ",(0,o.kt)("inlineCode",{parentName:"li"},"where python"),". The first line is the path to the Python in your environment (something like ",(0,o.kt)("inlineCode",{parentName:"li"},"/home/user/conda/envs/env_name/bin/python"),"). Copy it. Now create a new python file (not a notebook!), open it in VSCode and in the bottom-right, click on ",(0,o.kt)("inlineCode",{parentName:"li"},"Select interpreter")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"Python 3.x.x"),", a popup will appear with an option to ",(0,o.kt)("inlineCode",{parentName:"li"},"Enter interpreter path"),". Select that, paste in the copied path from the terminal and hit enter. Now if you open a notebook again, you should be able to select the environment (if not restart VSCode first).")),(0,o.kt)("h3",{id:"if-were-able-to-get-the-html-of-a-page-with-beautifulsoup-are-there-any-scenarios-where-it-wouldnt-be-enough-and-we-would-need-to-use-selenium"},"If we're able to get the HTML of a page with beautifulsoup, are there any scenarios where it wouldn't be enough and we would need to use selenium?"),(0,o.kt)("p",null,"Yes. Think about visiting an instagram profile: first only the skeleton of the page shows and then the pictures load in. beautifulsoup only sees the initial web page that is sent to you and therefore wouldn't be able to extract pictures as those are loaded in later with Javascript (remember, beautifulsoup speaks and knows only HTML and not Javascript). Furthermore, what if you want more than the first 15 pictures which are shown? You have to scroll down in order to trigger the loading of new pictures - you cannot do this with beautifulsoup."))}u.isMDXComponent=!0},3376:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/git_team_workflow-11a8f34ec961fc9b208ad329e321fef4.png"},2770:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/grouped_sales_matplotlib-d1a5d9b66bb842d2fff13e14761e3cc6.png"},9359:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/grouped_sales_seaborn-591c14db0d4e59168c19903379c9ab28.png"},2616:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/remotes-0aa04f24e7cd09d01fb6b8d7e28e3dce.jpg"}}]);