"use strict";(self.webpackChunktutoring=self.webpackChunktutoring||[]).push([[128],{3905:(e,t,n)=>{n.d(t,{Zo:()=>h,kt:()=>m});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=o.createContext({}),p=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},h=function(e){var t=p(e.components);return o.createElement(l.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),d=p(n),u=a,m=d["".concat(l,".").concat(u)]||d[u]||c[u]||i;return n?o.createElement(m,r(r({ref:t},h),{},{components:n})):o.createElement(m,r({ref:t},h))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:a,r[1]=s;for(var p=2;p<i;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},6272:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var o=n(7462),a=(n(7294),n(3905));const i={title:"Session 3 - Docker and docker compose",sidebar_position:5},r="Docker and docker compose",s={unversionedId:"session3",id:"session3",title:"Session 3 - Docker and docker compose",description:"Live demo: repository",source:"@site/docs/session3.md",sourceDirName:".",slug:"/session3",permalink:"/ids-tutoring/session3",draft:!1,editUrl:"https://github.com/KlemenVovk/ids-tutoring/edit/master/docs/session3.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"Session 3 - Docker and docker compose",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Session 2 - web scraping",permalink:"/ids-tutoring/session2"},next:{title:"Session 4 - Databases",permalink:"/ids-tutoring/session4"}},l={},p=[{value:"The story",id:"the-story",level:2},{value:"Chapter 1: the model",id:"chapter-1-the-model",level:3},{value:"Chapter 2: passing around Python scripts",id:"chapter-2-passing-around-python-scripts",level:3},{value:"Chapter 3: centralizing the model",id:"chapter-3-centralizing-the-model",level:3},{value:"Chapter 4: the need for isolation - virtual machines",id:"chapter-4-the-need-for-isolation---virtual-machines",level:3},{value:"Chapter 5: noisy neighbors",id:"chapter-5-noisy-neighbors",level:3},{value:"Chapter 6: simplifying deployment with docker compose",id:"chapter-6-simplifying-deployment-with-docker-compose",level:3},{value:"Chapter 7: adding another container into the mix",id:"chapter-7-adding-another-container-into-the-mix",level:3},{value:"Chapter 8: persisting container data",id:"chapter-8-persisting-container-data",level:3},{value:"Chapter 9: using environment variables for configuration and passing secrets",id:"chapter-9-using-environment-variables-for-configuration-and-passing-secrets",level:3},{value:"Further steps",id:"further-steps",level:2}],h={toc:p},d="wrapper";function c(e){let{components:t,...i}=e;return(0,a.kt)(d,(0,o.Z)({},h,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"docker-and-docker-compose"},"Docker and docker compose"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Live demo:")," ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3"},"repository")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Solve it yourself homework problem:")," TBA after the tutoring session."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"The goal is to motivate and introduce containerization (and Docker) through a practical story. The story is about a data scientist deploying a model in various ways, failing, and adjusting.")),(0,a.kt)("h2",{id:"the-story"},"The story"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"based on true events... :)")),(0,a.kt)("h3",{id:"chapter-1-the-model"},"Chapter 1: the model"),(0,a.kt)("p",null,"The company you are working at is producing metal parts of various dimensions (given by x, y and z) from different materials (steel, aluminum, copper) through different processes (turning, drilling, milling). The parts can be of varying complexities (an integer between 1 and 10), and for each we have the time it took to produce it in minutes. This is also our target variable. The hope is that the model will be able to predict how long a certain part will take to produce, which will help with scheduling different parts and increase efficiency (therefore increasing profits as more parts can be produced)."),(0,a.kt)("p",null,"A few lines from the dataset:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-csv"},"x_cm,y_cm,z_cm,material,complexity,process,time_min\n31.95,19.82,12.55,aluminum,7,turning,630\n38.61,5.25,8.19,steel,1,drilling,771\n34.11,16.9,8.8,steel,5,drilling,659\n31.8,22.72,5.26,aluminum,5,drilling,590\n")),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"Note: this is a synthetically generated dataset, the generating code can be found ",(0,a.kt)("a",{parentName:"em",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/0_preparation"},"here"))),(0,a.kt)("p",null,"You do all the steps of the usual data science pipeline and come up with a random forest model that seems to work well for what you are trying to do. The code for the model is available ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/blob/master/live_demo/1_traditional/model.py"},"here"),"."),(0,a.kt)("h3",{id:"chapter-2-passing-around-python-scripts"},"Chapter 2: passing around Python scripts"),(0,a.kt)("p",null,"You are certain that your model can increase profits. However this will only happen if people actually use your model and that will only happen if it's easy to use."),(0,a.kt)("p",null,"Here comes the first problem: your model currently runs pretty much only on your machine and only you know how to run it. Running python scripts (in the correct environments with correct packages) is NOT really something you want to explain to non-tech-savy people. You need to figure something out. After some thinking, you figure, it's only the mechanical engineering department manager that needs to use this, so you can just borrow their laptop for 20 minutes, install python, create the environment, and give a short lesson on how to use the model, ",(0,a.kt)("strong",{parentName:"p"},"but it's ok, you only have to do it once"),". You create a ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/blob/master/live_demo/1_traditional/predict.py"},"simple Python script that allows using the model for prediction")),(0,a.kt)("p",null,"So the current way to use the model is as follows: you pretrain the model and export it as a pickle file. This pickle file along with the prediction script is given to the manager. To predict it's then enough to have the model in the same folder as the script and run the script with the input features:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# python predict.py model_location, x, y, z, material, complexity, process\npython predict.py model.pkl 30 15 10 steel 5 milling\n")),(0,a.kt)("p",null,"The manager learns how to use the model, company profits increase, everyone is happy. Time passes and due to increased efficiency because of your model, the company can start producing 1 more type of part, which your model also needs to predict. This requires you to create a new version of the model, go to the manager, borrow his laptop again, recreate the environment and update the model on his PC (or would you rather explain Git and Python environments to him so he can do it himself?). Furthermore, the manager is getting overwhelmed with the number of parts he has to process and would like to delegate some of the work to 4 other people. Now you need to do the same installation and explaining for them too. You just learned the hard way that passing python scripts around to deploy models is NOT the way to go. You need to somehow centralize the access to the model so that you have only 1 deployment that everyone uses."),(0,a.kt)("h3",{id:"chapter-3-centralizing-the-model"},"Chapter 3: centralizing the model"),(0,a.kt)("p",null,"Remember when we talked about APIs (specifically ",(0,a.kt)("a",{parentName:"p",href:"https://klemenvovk.github.io/ids-tutoring/session1#useful-external-libraries"},"using FastAPI to create an API for your model"),")? You realize it would be way better if you could talk to your IT department and they gave you access to one of their servers where you could deploy your API and then everyone can use it through their web browser."),(0,a.kt)("p",null,"Ok, you cushion your chair, oil your keyboard and code out an API for your model, all in 1 night of extreme red-bull fuelled extravaganza. Now you send an email to IT asking for access to a server so that you can deploy your model. IT gives you SSH access to a server (remember when we talked about learning how to use the terminal and ditch the GUI?). Ok, now you spend the whole day preparing the operating system, and everything required (updating system packages, logging into Github, installing python, cloning the repository, creating the environment, etc.), ",(0,a.kt)("strong",{parentName:"p"},"but it's ok, you only have to do this once"),". Luckily, you managed to deploy your API on the server and everyone can access through their web browser. There is also no need to do an in-depth explanation on how to use the API because you provided the documentation too (remember when we talked about the benefit of FastAPI and similar tools that will automatically generate documentation for you?). Now when you need to update it or the model behind it, you can do it yourself on the server and that's it. Days pass by, everything seems to be in order. People are using your model and the company is working more efficiently."),(0,a.kt)("admonition",{type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"DO NOT use SSH with passwords. There is no excuse, always use public/private key pairs for SSH authentication. Stress this to anyone who gives you SSH access with a password. You can use the public key you have on your Github for SSH access, so people who are giving you access can use tools like ",(0,a.kt)("a",{parentName:"p",href:"http://man.he.net/man1/ssh-import-id-gh"},"ssh-import-id")," to import your keys just by knowing your Github username.")),(0,a.kt)("p",null,"The only thing we added to the previous chapter code is a script for the API:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from predict import predict_one # the function from our predict.py script\nfrom fastapi import FastAPI\nimport time\n\napp = FastAPI()\n\n@app.get(\"/predict\")\ndef predict(x: float, y: float, z: float, material: str, complexity: int, process: str):\n    time.sleep(5) # Simulate a long computation, we'll motivate this later\n    y_pred = predict_one('model.pkl', x, y, z, material, complexity, process)\n    return {'time_min': y_pred}\n")),(0,a.kt)("p",null,"The API can be run by installing the requirements from ",(0,a.kt)("inlineCode",{parentName:"p"},"requirements.txt")," and running (from the ",(0,a.kt)("inlineCode",{parentName:"p"},"2_api")," folder):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'# the "api" is referring to the api.py file, and the "app" is referring to the app = FastAPI() object inside the api.py file\nuvicorn api:app\n')),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"Uvicorn is basically a server that can handle multiple connections to your app (in this case the FastAPI api) at the same time. There are also tools like ",(0,a.kt)("a",{parentName:"p",href:"https://gunicorn.org/"},"Gunicorn")," which will run multiple instances of your API/web app in the background in parallel in case you have many requests, and divide the requests equally between the instances, allowing you to scale.")),(0,a.kt)("h3",{id:"chapter-4-the-need-for-isolation---virtual-machines"},"Chapter 4: the need for isolation - virtual machines"),(0,a.kt)("p",null,"One morning your phone starts blowing up with people saying that your model is inaccessible/not working. You immediately become suspicious as you haven't changed anything. You SSH into the server to investigate. You can see that your Python app isn't running anymore, but that's about it since you didn't bother with implementing logging. After contacting IT you find out that the server was restarted at midnight to apply security updates. However, you are sure that you have implemented auto startup of your API on boot, so you go to double check. You find out that your startup script has been replaced with someone else's, so it's not even being executed. So someone accidentally destroyed your deployment as a side effect of deploying theirs and you only found out because of the system update."),(0,a.kt)("p",null,"You start thinking again. There has to be a better way of doing this. You can't just sit tight and hope no one else accidentally destroys your deployment. If only you could have a system that was just yours and isolated from everything else, yet running on the current company infrastructure. You search the web and come across these things called virtual machines and find out that it's basically a virtual computer created inside your computer and is completely isolated from it. You inform IT of this possibility and after some complaining they create a virtual machine for you and give you SSH access to it. This way they have created a tiny, less powerful computer on their server, just for you. Ok, now you spend the whole day preparing the operating system, and everything required (updating system packages, logging into Github, installing python, cloning the repository, creating the environment, setting up API autostart on boot, etc.), ",(0,a.kt)("strong",{parentName:"p"},"but it's ok, you only have to do this once")," (do you start to see a pattern?). You manage to get everything back up and running in 2 days. Things seem to be back on track."),(0,a.kt)("p",null,"Below is a screenshot from a VM hypervisor (a hypervisor is just a fancy name for a program that manages virtual machines) known as Proxmox. You can see that it's just a computer inside a computer."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Proxmox virtual environment",src:n(1080).Z,width:"1899",height:"923"})),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"You usually don't get access to a GUI if the VM is somewhere on a server. This is because GUIs waste resources, and configuration through SSH is quicker (and often easier) than using a remote GUI. This is also one of the reasons why specialized Linux distributions exist just for servers - e.g. ",(0,a.kt)("a",{parentName:"p",href:"https://ubuntu.com/server"},"Ubuntu Server")," (which is for the most part just Ubuntu without a GUI).")),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"There are two groups of hypervisors - type 1 and type 2. A type 1 hypervisor (",(0,a.kt)("a",{parentName:"p",href:"https://www.vmware.com/products/esxi-and-esx.html"},"VMWare ESXi"),") operates directly on the hardware, serving as the host operating system for virtual machines without needing an underlying OS. It is more efficient and is typically used in enterprise environments. In contrast, a Type 2 hypervisor (",(0,a.kt)("a",{parentName:"p",href:"https://www.vmware.com/products/workstation-pro.html"},"VMWare Workstation"),", ",(0,a.kt)("a",{parentName:"p",href:"https://www.virtualbox.org/"},"VirtualBox"),") runs on top of an existing operating system and is more suitable for personal or development use, but tends to have lower performance compared to Type 1. In other words: a type 2 hypervisor is just a program that you install on your OS, a type 1 hypervisor IS an OS. If you want to try VMs on your own, just install a type 2 hypervisor on your OS.")),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"There exist tools that automate creation and configuration of VMs. If you want to read more, check out ",(0,a.kt)("a",{parentName:"p",href:"https://www.vagrantup.com/"},"Vagrant"),", ",(0,a.kt)("a",{parentName:"p",href:"https://www.vagrantup.com/"},"Terraform"),", and ",(0,a.kt)("a",{parentName:"p",href:"https://www.packer.io/"},"Packer"),". There are also general IT automation frameworks such as ",(0,a.kt)("a",{parentName:"p",href:"https://www.ansible.com/"},"Ansible"),". The lines between them are generally blurred (e.g. you can use Vagrant for everything, or use Terraform just to create a VM and Ansible to configure it etc.)")),(0,a.kt)("h3",{id:"chapter-5-noisy-neighbors"},"Chapter 5: noisy neighbors"),(0,a.kt)("p",null,"In your regular end of the week meeting, you explain why the crash from Chapter 4 ocurred, and how you addressed it and made sure it doesn't happen again. Other people who have stuff deployed on the server see the benefit of VMs and start asking IT for their own VMs. This works for some time, and IT is creating VMs. The server has 64 GB of RAM, and they are giving everyone the same VMs with 8GBs of RAM assigned. Soon they run out of RAM to give out, and ask management for better hardware. Management declines to avoid expenses, but IT figures that no one is using the whole 8GB of RAM, so theoretically, they can assign more VMs and as long as each VM is not using all RAM, it should be fine. This works up to a point, but then some people deploy heavier deployments and start using the whole RAM, which degrades the experience for others (because the same portion of RAM is allocated to multiple VMs) - the so called ",(0,a.kt)("a",{parentName:"p",href:"https://www.techtarget.com/searchcloudcomputing/definition/noisy-neighbor-cloud-computing-performance"},"noisy neighbor problem"),". IT starts threatening removal of VMs and things start to grind to a halt between logistic and technical problems."),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"The noisy neighbor problem can happen with many resources, not just RAM, but also CPU, network bandwidth, disk IO etc.")),(0,a.kt)("p",null,"Again, you figure there has to be a better way to do this. You agree with IT that you don't need a machine with 8GB of RAM for your simple model, and your VM is therefore hogging resources it doesn't need, but you also need isolation from others and don't want to return to the pre-VM era. After some googling you run into the concept of containers, which seems like it's exactly what you need. Recall, virtual machines emulate entire operating systems, providing isolation but incurring higher resource overhead and longer startup times. Think of VMs as mini-computers within your computer. On the other hand, containers encapsulate applications and their dependencies, sharing the host OS kernel. They are lightweight and start almost instantly. Picture containers as self-sufficient, portable packages that can run consistently across various environments. For data scientists, the choice boils down to resource efficiency and ease of deployment \u2013 VMs offer stronger isolation but at a cost, while containers provide agility and consistency with minimal overhead."),(0,a.kt)("p",null,"To give you some ballpark numbers: VMs can take minutes to boot, containers start in seconds. VMs usually use 20 GBs of disk space (whole OS + everything you install), containers use a (few) hundred megabytes. VMs at minimum require 2GB or 4GB of RAM, containers use a (few) tens to a (few) hundred megabytes at most. Of course, containers can also be very heavy and slow, depending on the applications they are running."),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"Containers are not strictly better than VMs. Sometimes you NEED a VM. For example, you might need to run a Windows only application - this isn't really feasible with docker containers. It's even worse if you need an older Windows version like Windows XP. In these cases you would turn to a VM. If you don't need the degree of isolation that VMs provide, and you don't need to run non-Linux stuff, it's a good idea to try with a container first, and use a VM only as a last resort.")),(0,a.kt)("admonition",{type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"While VMs and containers offer isolation, you have to be careful. For example if a VM is connected to your network, then if someone breaks into the VM, it automatically has network access to all the other devices in your network. Same goes for mapping folders - sometimes you want to map a folder from your host to a VM. This means that if a virus happens to get into the mapped directory, it is also on the host!")),(0,a.kt)("p",null,"So to run our API we need a Python installation with the libraries from requirements.txt and the code. In other words we need to perform the following:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Get a OS with Python installed."),(0,a.kt)("li",{parentName:"ol"},"Install everything from requirements.txt"),(0,a.kt)("li",{parentName:"ol"},"Copy the code and the model"),(0,a.kt)("li",{parentName:"ol"},"Run our API")),(0,a.kt)("p",null,"We need to define a container that will perform the above steps. A container is defined by a ",(0,a.kt)("inlineCode",{parentName:"p"},"Dockerfile")," (a nice cheatsheet for everything Docker is available ",(0,a.kt)("a",{parentName:"p",href:"https://dockerlabs.collabnix.com/docker/cheatsheet/"},"here"),"). From the Dockerfile you can build container images. You can then use these images to launch a container."),(0,a.kt)("p",null,"Let's tackle step 1. We need to find a base container image. We need an OS with Python. If we search ",(0,a.kt)("a",{parentName:"p",href:"https://hub.docker.com/"},"Docker Hub")," (a repository of container images) for Python we find the ",(0,a.kt)("a",{parentName:"p",href:"https://hub.docker.com/_/python"},"official Python container image")),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Python on Docker Hub",src:n(6636).Z,width:"1330",height:"897"})),(0,a.kt)("p",null,"You notice there are many tags, like ",(0,a.kt)("inlineCode",{parentName:"p"},"3.12.0-bookworm"),". These denote different versions and base images (just like we are using the Python container image as a base for our container, the Python container image uses Debian - a linux distribution as its base). In this case ",(0,a.kt)("inlineCode",{parentName:"p"},"3.12.0")," is the Python version in the image, and ",(0,a.kt)("inlineCode",{parentName:"p"},"bookworm")," is the Debian version (",(0,a.kt)("a",{parentName:"p",href:"https://www.debian.org/releases/bookworm/"},"Debian 12 - bookworm"),")."),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"you may also find tags like ",(0,a.kt)("inlineCode",{parentName:"p"},"-alpine")," which means that container image is using the Alpine linux distribution as it's base. Alpine is a really small Linux distribution which greatly reduces attack surface for breaking in/out of containers and resource consumption.")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Step 1: Get a OS with Python installed.")," Let's define our Dockerfile (addresses step 1):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"# this is the image:tag from Docker HUB\nFROM python:3.12-bullseye\n...\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Step 2: Install everything from requirements.txt.")," Now we need to install libraries from requirements.txt. However, the container is currently stock - it doesn't have our requirements.txt, so we must first copy the requirements.txt from our computer to the container. Once we have it, we can run pip install."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"...\n# Where we are in the container (basically equivalent to 'cd /app')\nWORKDIR /app\n\n# Set up python environment\n# This is the first thing so that docker can cache it (changes later/below in the file will not invalidate this layer)\nCOPY requirements.txt /app\nRUN pip install -r requirements.txt\n...\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Step 3: Copy the code and the model.")," Same as with requirements.txt, the container currently doesn't have our code (it's just the base container from Docker Hub, with the requirements.txt copied from the previous step). Let's copy the code and the model:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-dockerfile"},"# Copy code\n# If copying a directory, the destination must end with a slash\nCOPY src/* /app/\n\n# Copy model\nCOPY model.pkl /app\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Step 4: Run our API.")," Finally we need to run Uvicorn as in Chapter 3. Remember when we launched our API in chapter 3, the output was the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"\u276f uvicorn api:app             \nINFO:     Started server process [10995]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n")),(0,a.kt)("p",null,"From this we know, that the API is by default accessible ",(0,a.kt)("inlineCode",{parentName:"p"},"http://127.0.0.1:8000")," (equivalently, ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:8000"),"). Pay attention to the port number (8000)."),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"A port is simply a mechanism of accessing different applications on the same IP/destination. i.e. we could have FastAPI running on port 8000, and then a completely separate webpage running on port 3000. So if we want to access the FastAPI, we go to ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:8000")," and if we want to access the website we go to ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:3000"),". Note that the IP address/domain (localhost) is the same for both as they are running on the same computer!")),(0,a.kt)("p",null,"Therefore we have to tell the container to make the port 8000 accessible from the outside. Then we have to run Uvicorn:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-dockerfile"},'# Expose port 8000 from the container to the host\nEXPOSE 8000\n\n# Run the app\n# note how below we had to pass an array of arguments, if we were running this from the terminal, the equivalent would be\n# uvicorn api:app --host 0.0.0.0 --port 8000\nCMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]\n')),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"--host 0.0.0.0")," is a common occurrence across different servers, it just tells Uvicorn that it should listen on port 8000 for connections from anywhere, by default it only listens on port 8000 for connections from localhost (in this case the container) - in other words, without the ",(0,a.kt)("inlineCode",{parentName:"p"},"--host 0.0.0.0"),", the API would only be accessible from ",(0,a.kt)("inlineCode",{parentName:"p"},"http://localhost:8000")," INSIDE the container. Remember, ",(0,a.kt)("inlineCode",{parentName:"p"},"localhost")," on your host maps to your PC, and ",(0,a.kt)("inlineCode",{parentName:"p"},"localhost")," in the container maps to the container!"),(0,a.kt)("p",null,"That's it! Now we only have to build the docker image, and give it a tag (similar to how Python had the tag ",(0,a.kt)("inlineCode",{parentName:"p"},"3.12.0-bookworm"),"). Let's keep it simple and tag our image ",(0,a.kt)("inlineCode",{parentName:"p"},"idsdemo"),". From the directory with the Dockerfile run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# the dot '.' refers to the current directory (that's where the Dockerfile is)\ndocker build . -t idsdemo\n")),(0,a.kt)("p",null,"Now that we have our image ready, we can create a container from it with:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"docker run -p 4000:8000 idsdemo\n")),(0,a.kt)("p",null,"Notice the ",(0,a.kt)("inlineCode",{parentName:"p"},"-p 4000:8000"),". To make our container accessible from the host, we have to map a port on the host to a port in the container. The format is always ",(0,a.kt)("inlineCode",{parentName:"p"},"-p HOST:CONTAINER"),". We exposed the port 8000 in the container (with ",(0,a.kt)("inlineCode",{parentName:"p"},"EXPOSE 8000"),"), now we can pick any, non used port on the host and map to it. In this case, we picked 4000."),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"This is also an advantage of using Docker. You know that Uvicorn by default runs on port 8000. What if you want to have two different APIs (so two different Uvicorns)? Well we can containerize both and run one with ",(0,a.kt)("inlineCode",{parentName:"p"},"-p 4000:8000")," and the other with ",(0,a.kt)("inlineCode",{parentName:"p"},"-p 5000:8000"),". This way we don't have to reconfigure Uvicorn to use a different port. Some applications make it VERY hard to move them to a different port, so this is an easy solution.")),(0,a.kt)("p",null,"The code for this chapter can be found ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/3_containers_basic/api"},"here")),(0,a.kt)("h3",{id:"chapter-6-simplifying-deployment-with-docker-compose"},"Chapter 6: simplifying deployment with docker compose"),(0,a.kt)("p",null,"Running ",(0,a.kt)("inlineCode",{parentName:"p"},"docker build")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"docker run")," with the correct parameters quickly becomes cumbersome. This is where ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose")," comes in. It's a way to define the build and run commands in a single configuration file that we can then deploy with a single command. The file is a YAML file named ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml"),"."),(0,a.kt)("p",null,"Below is the equivalent of Chapter 5 in docker compose"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"version: '3'\nservices:\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    ports:\n      - 4000:8000\n")),(0,a.kt)("p",null,"The above tells to use docker compose version 3. Then it only defines 1 service (called api), the image for the service is built from the ",(0,a.kt)("inlineCode",{parentName:"p"},"./api")," subfolder and the Dockerfile is in ",(0,a.kt)("inlineCode",{parentName:"p"},"./api/Dockerfile"),". The it also maps the port from the host to the container."),(0,a.kt)("p",null,"We can deploy the above by running"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"docker compose up\n")),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},(0,a.kt)("inlineCode",{parentName:"p"},"docker compose")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose")," are equivalent. They both exist because ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose")," was a standalone, separate project (so it was a different command), and then Docker adopted it as a subcommand of the ",(0,a.kt)("inlineCode",{parentName:"p"},"docker")," command.")),(0,a.kt)("admonition",{type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"If you are changing anything in your Dockerfile, you sometimes have to force a rebuild of the container images by running ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose up --build"))),(0,a.kt)("p",null,"Other commands you should know:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"docker compose up -d # runs the stack in the background, -d stands for detach\ndocker compose down # stops the containers and deletes them\n# I personally recommend avoiding using the below two, containers are like cattle and should always be replaced, never restarted.\ndocker compose start # starts the containers (if they were stopped at some point)\ndocker compose stop # stops the containers (but doesn't delete them)\n")),(0,a.kt)("p",null,"The code for this chapter can be found ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/4_containers_compose"},"here"),"."),(0,a.kt)("h3",{id:"chapter-7-adding-another-container-into-the-mix"},"Chapter 7: adding another container into the mix"),(0,a.kt)("p",null,"It starts bothering you that your model is so slow on prediction (remember the ",(0,a.kt)("inlineCode",{parentName:"p"},"time.sleep(5)")," we added to the API to simulate long computation?). There are a lot of common parts for which the dimensions don't change and it would be a good idea the prediction for them. So when someone asks for a prediction that has already been done before, you don't predict the value again, but return the stored value from the original prediction. The correct terminology for this is caching."),(0,a.kt)("p",null,"To introduce caching, we will use/deploy ",(0,a.kt)("a",{parentName:"p",href:"https://redis.io/"},"Redis"),", which is a key-value database (a dictionary in Python). It's the defacto standard in the industry for such applications. For all you need to know, it's just a REALLY fast dictionary."),(0,a.kt)("p",null,"Since Redis is a separate application from our API, we will introduce another container. A quick search on the Docker Hub yields the ",(0,a.kt)("a",{parentName:"p",href:"https://hub.docker.com/_/redis"},"official Redis image"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Redis on Docker Hub",src:n(7853).Z,width:"1296",height:"858"})),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"Always try to stick to the rule of 1 app per container. Containers are meant to be thin, disposable, and modular. Throwing multiple apps in them makes them a sort of a budget VM.")),(0,a.kt)("p",null,"Luckily, we don't need any custom tailored solution like we did with our FastAPI container (we don't need to install anything, we just need default Redis). So all we need to do is use that image in our ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"version: '3'\nservices:\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    ports:\n      - 4000:8000\n    depends_on:\n      - rediscache\n  rediscache:\n    image: redis:alpine\n    container_name: shiny-redis-cache\n    # Do we need to port forward this? Remember redis is only used \"internally\" - so inside the docker network from the api container, you are never accessing it from the host, this is why you don't want to port forward here.\n    # ports:\n    #   - 6379:6379\n\n")),(0,a.kt)("p",null,"Notice the ",(0,a.kt)("inlineCode",{parentName:"p"},"depends_on:"),", this just means that the ",(0,a.kt)("inlineCode",{parentName:"p"},"rediscache")," service must be started before the API, which makes sense, as we want our cache to be accessible, otherwise, the API might try to connect before it's ready and fail."),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"Always search Docker Hub for premade images that you need to modify as little as possible. Of course, there is nothing stopping you from just starting with a Ubuntu base container image and then installing Redis in that through commands in the Dockerfile, but this is introducing unneeded maintenance."),(0,a.kt)("p",{parentName:"admonition"},"Also make sure to always read the Docker Hub page of your image as it often contains all the documentation you really need")),(0,a.kt)("p",null,"Lastly, we just change our ",(0,a.kt)("inlineCode",{parentName:"p"},"api.py")," to first check if the prediction was already made before (and return the saved value), or make the prediction and save it for future use."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from predict import predict_one\nfrom fastapi import FastAPI\nimport redis\nimport time\n\n# Host is the container name - docker compose automatically takes care of networking containers from the same docker-compose.yml file\nr = redis.Redis(host='shiny-redis-cache', port=6379, decode_responses=True)\napp = FastAPI()\n\n@app.get(\"/predict\")\ndef predict(x: float, y: float, z: float, material: str, complexity: int, process: str):\n    key = f'{x}-{y}-{z}-{material}-{complexity}-{process}'\n    if r.exists(key):\n        return {'time_min': float(r.get(key))}\n    time.sleep(5) # Simulate a long computation, we'll motivate this later\n    y_pred = predict_one('model.pkl', x, y, z, material, complexity, process)\n    r.set(key, y_pred)\n    return {'time_min': y_pred}\n")),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"You can notice another advantage of Docker and docker-compose. See how we could connect to the Redis container just by using the container name ",(0,a.kt)("inlineCode",{parentName:"p"},"shiny-redis-cache")," as the host instead of some IP? Remember, unless explicitly changed, all containers in the same ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file automatically see each other and can communicate. A container can be in multiple networks, or in none for isolation. For further reading see ",(0,a.kt)("a",{parentName:"p",href:"https://docs.docker.com/compose/networking/"},"here"),".")),(0,a.kt)("p",null,"That's it! Now if we run everything with ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose up")," (see how we still use only 1 command?), our API will cache predictions and return the saved value if possible, making our API far more responsive."),(0,a.kt)("admonition",{type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"Caching is a common source of errors in practice. Be careful with it, and introduce it at the very end. If possible, test without cache. For example: if you change the model, it's possible that the cache would still be returning the old value (from the previous model)...")),(0,a.kt)("p",null,"The code for this chapter can be found ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/5_containers_redis"},"here"),"."),(0,a.kt)("h3",{id:"chapter-8-persisting-container-data"},"Chapter 8: persisting container data"),(0,a.kt)("p",null,"You are happy with your caching, however, you would like to persist the cache between restarts of the container. Also, you would like to be able to change the model while the container is live. In other words, you need to save the Redis data on your host, and you need to be able to change the ",(0,a.kt)("inlineCode",{parentName:"p"},"model.pkl")," file live."),(0,a.kt)("admonition",{type:"note"},(0,a.kt)("p",{parentName:"admonition"},"This is probably not something you would use (you shouldn't really persist cache and change models at the same time), but I included it for DEMO purposes.")),(0,a.kt)("p",null,"This is where you use volumes and volume mapping. Similarly, as we mapped the port from host to a container, we can also map a directory from the host to a directory inside a container. So any changes on any end are immediately visible on the other. This mapping is by default bidirectional (reads and writes on both ends are allowed), however it ",(0,a.kt)("a",{parentName:"p",href:"https://docs.docker.com/storage/volumes/#use-a-read-only-volume"},"can be restricted to a readonly etc."),". Like with ports, the format is ",(0,a.kt)("inlineCode",{parentName:"p"},"host:port")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"version: '3'\nservices:\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    ports:\n      - 4000:8000\n    depends_on:\n      - rediscache\n    volumes:\n      - ./model.pkl:/app/model.pkl\n  rediscache:\n    image: redis:alpine\n    container_name: shiny-redis-cache\n    volumes:\n      - ./redisdata:/data\n    command: redis-server --appendonly yes\n")),(0,a.kt)("p",null,"Instead of copying the model in the Dockerfile, we chose to map it from host to the container. We don't need to change any of our Python code, as the ",(0,a.kt)("inlineCode",{parentName:"p"},"model.pkl")," file will be accessible in the same place as before. The Python app (nor the container) don't know that this is actually a file on the host machine."),(0,a.kt)("p",null,"Similarly, we mapped the ",(0,a.kt)("inlineCode",{parentName:"p"},"/data")," folder inside the Redis container (this is where Redis by default stores its DB, seen on the Redis container image Docker Hub page) to a folder ",(0,a.kt)("inlineCode",{parentName:"p"},"redisdata")," on the host. This way, when we delete the container, the data stays, and when a new container is started, it uses the data from the previous one."),(0,a.kt)("p",null,"The code for this chapter can be found ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/6_containers_persistence"},"here")),(0,a.kt)("h3",{id:"chapter-9-using-environment-variables-for-configuration-and-passing-secrets"},"Chapter 9: using environment variables for configuration and passing secrets"),(0,a.kt)("p",null,"Lastly, we would like to secure our Redis database. This is usually not needed in practice, as the Redis container isn't even accessible from the outside (remember we didn't forward any ports for the Redis container, therefore it can only be accessed from other containers in the ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file.)."),(0,a.kt)("p",null,"A password is sensitive data, remember when we talked about ",(0,a.kt)("a",{parentName:"p",href:"http://localhost:3000/ids-tutoring/session1#useful-external-libraries"},"using environment variables and .env files for sensitive data (specifically python-dotenv library)"),"? Looking at the Redis documentation, the password can be set with an environment variable ",(0,a.kt)("inlineCode",{parentName:"p"},"REDIS_PASSWORD"),". Let's create an ",(0,a.kt)("inlineCode",{parentName:"p"},".env")," file for this"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"REDIS_PORT: 6379\nREDIS_PASSWORD: thisverysecuredemopassword\n")),(0,a.kt)("p",null,"I also added ",(0,a.kt)("inlineCode",{parentName:"p"},"REDIS_PORT")," (on which port of the container Redis listens) just to show that this can be used for configuration as well. Now we just tell docker compose to use this env file for the api and for the rediscache container.:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"version: '3'\nservices:\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    ports:\n      - 4000:8000\n    depends_on:\n      - rediscache\n    volumes:\n      - ./model.pkl:/app/model.pkl\n    env_file:\n     - .env\n    # You could also use 'environment' instead of env_file etc., but this is not safe for sensitive data as docker-compose.yml is usually stored in a repository.\n    # environment:\n    #  - REDIS_PASSWORD=redispassword\n  rediscache:\n    image: redis:alpine\n    container_name: shiny-redis-cache\n    volumes:\n      - ./redisdata:/data\n    # Notice how we use the REDIS_PASSWORD variable here, because the command is the last thing that is run when the container is started, therefore the env_file and variables from it are already imported and we can use them.\n    command: redis-server --appendonly yes --requirepass $REDIS_PASSWORD\n    env_file:\n      - .env\n")),(0,a.kt)("p",null,"The last thing to do is to tell Python to look for the Redis password in the ",(0,a.kt)("inlineCode",{parentName:"p"},"REDIS_PASSWORD")," environment variable. Here we don't need to use ",(0,a.kt)("inlineCode",{parentName:"p"},"python-dotenv")," library, as the ",(0,a.kt)("inlineCode",{parentName:"p"},".env")," file is already loaded by docker compose! Modifying the ",(0,a.kt)("inlineCode",{parentName:"p"},"api.py")," file:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"...\nr = redis.Redis(host='shiny-redis-cache', port=6379, decode_responses=True, password=os.environ['REDIS_PASSWORD'])\n...\n")),(0,a.kt)("p",null,"That's it. Again, we run the stack with ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose up"),"."),(0,a.kt)("p",null,"At this point we have covered many basic concepts of Docker. However there are many more, don't be afraid to delve into the documentation."),(0,a.kt)("p",null,"The code for this chapter can be found ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/KlemenVovk/ids-tutoring-s3/tree/master/live_demo/7_containers_env"},"here"),"."),(0,a.kt)("h2",{id:"further-steps"},"Further steps"),(0,a.kt)("p",null,"To mention some possible next steps that we can discuss turing the tutoring session:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"multistage builds"),(0,a.kt)("li",{parentName:"ul"},"scaling"),(0,a.kt)("li",{parentName:"ul"},"container orchestrators (Kubernetes)"),(0,a.kt)("li",{parentName:"ul"},"deployment to the cloud"),(0,a.kt)("li",{parentName:"ul"},"devcontainers"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/awesome-selfhosted/awesome-selfhosted"},"awesome-selfhosted"))))}c.isMDXComponent=!0},1080:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/pve-66255ee905b962aef66ef58362958dbe.png"},6636:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/pythonhub-c3cec79e82457c420fce70a845edc35d.png"},7853:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/redishub-c39216524e569a60a810cd436b3405fa.png"}}]);